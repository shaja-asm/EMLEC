{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaja-asm/EMLEC/blob/dev/Assignment_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKct8b3_pht_"
      },
      "source": [
        "# **Assignment: Detect Hand Guestures**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8duTEknwK5xX"
      },
      "source": [
        "# Requirement:  \n",
        "* Build a Computer Vision Application to Detect Hand Gestures.\n",
        "* Focus is on 3 Gestures. Rock, Paper, Scissor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqc2aIIIzgq"
      },
      "source": [
        "# INSTRUCTIONS:\n",
        "* Make your own copy of the Notebook before starting the assignment.\n",
        "  **File** -> **save a copy in Drive**\n",
        "\n",
        "* Fill the place holders in the notebook which are indicated with the 'FILL:' Key word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPLghmkLBGIJ"
      },
      "source": [
        "## Download & Extract Rock-Paper-Scissor Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcxoND0RMfIJ"
      },
      "source": [
        "Link to the dataset: https://www.tensorflow.org/datasets/catalog/rock_paper_scissors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZGYdFAdkLbva"
      },
      "outputs": [],
      "source": [
        "!mkdir ./tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uwHxiNVlBqX"
      },
      "source": [
        "Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vOcL5EcdBAcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5127990c-75e1-4252-ceb5-fe0cd57c7428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-07 05:25:42--  https://storage.googleapis.com/download.tensorflow.org/data/rps.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.207, 142.251.31.207, 142.251.18.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 200682221 (191M) [application/zip]\n",
            "Saving to: ‘./tmp/rps.zip’\n",
            "\n",
            "./tmp/rps.zip       100%[===================>] 191.38M  30.3MB/s    in 7.6s    \n",
            "\n",
            "2024-07-07 05:25:50 (25.3 MB/s) - ‘./tmp/rps.zip’ saved [200682221/200682221]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/download.tensorflow.org/data/rps.zip \\\n",
        "    -O ./tmp/rps.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_QkqDhulERS"
      },
      "source": [
        "Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OhJ69whX_r5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483a9f14-6919-4ccd-83be-0a88922ecc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-07 05:25:54--  https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.218.207, 142.251.31.207, 142.251.18.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.218.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29516758 (28M) [application/zip]\n",
            "Saving to: ‘./tmp/rps-test-set.zip’\n",
            "\n",
            "./tmp/rps-test-set. 100%[===================>]  28.15M  21.8MB/s    in 1.3s    \n",
            "\n",
            "2024-07-07 05:25:56 (21.8 MB/s) - ‘./tmp/rps-test-set.zip’ saved [29516758/29516758]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/download.tensorflow.org/data/rps-test-set.zip \\\n",
        "    -O ./tmp/rps-test-set.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72WK_uAxlyxv"
      },
      "source": [
        "## Use Zipfile to extract the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywCilQAWnrFI"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSlb5rtfQJea"
      },
      "outputs": [],
      "source": [
        "def extract_file(src, dest):\n",
        "  # opening the zip file in READ mode\n",
        "  with zipfile.ZipFile(src, 'r') as zip:\n",
        "      # extracting all the files\n",
        "      print(f'Extracting all the files from {src}...')\n",
        "      zip.extractall(dest)\n",
        "      print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrsxN5nTRki-"
      },
      "outputs": [],
      "source": [
        "extract_file(src='./tmp/rps.zip', dest='./data')\n",
        "extract_file(src='./tmp/rps-test-set.zip', dest='./data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MapqKrRDLGch"
      },
      "outputs": [],
      "source": [
        "def get_image_counts(parent_folder, dataset_name):\n",
        "  rock_dir = os.path.join(parent_folder, 'rock')\n",
        "  paper_dir = os.path.join(parent_folder, 'paper')\n",
        "  scissors_dir = os.path.join(parent_folder, 'scissors')\n",
        "\n",
        "  print(f'total {dataset_name} rock images: {len(os.listdir(rock_dir))}')\n",
        "  print(f'total {dataset_name} paper images: {len(os.listdir(paper_dir))}')\n",
        "  print(f'total {dataset_name} scissors images: {len(os.listdir(scissors_dir))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ0Q4eUYPgFX"
      },
      "outputs": [],
      "source": [
        "get_image_counts(parent_folder='./data/rps', dataset_name='training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AG4TOmP3QAk5"
      },
      "outputs": [],
      "source": [
        "get_image_counts(parent_folder='./data/rps-test-set', dataset_name='testing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gUAVmRMuQDh"
      },
      "source": [
        "# Training Pipeline Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRR8n-UguZCX"
      },
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_qw5YX3phuA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPE2i1jSfRNL"
      },
      "source": [
        "### 2.1. Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYkwyKYnphuD"
      },
      "outputs": [],
      "source": [
        "for label in ['rock', 'paper', 'scissors']:\n",
        "  im_folder = f'./data/rps/{label}'\n",
        "  im_count = 2\n",
        "  for im_name in  os.listdir(im_folder)[:im_count]:\n",
        "      im_path = os.path.join(im_folder, im_name)\n",
        "      img = Image.open(im_path).convert('RGB')\n",
        "      img = np.asarray(img)\n",
        "      # plt.title(f'Label: { y_test[i]}')\n",
        "      plt.imshow(img)\n",
        "      plt.show()\n",
        "  print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty0IeIhxWRUv"
      },
      "source": [
        "# Use Image Data Generator to Pre-process and to Feed data to the training pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OEAA9m6WakJ"
      },
      "source": [
        "## Requirement:\n",
        "### 1.Resize Images to (128, 128)\n",
        "### 2.Rescale images to (0 - 1.) range\n",
        "### 3. Use batch_size: 64\n",
        "### 4.Augment only the training data.\n",
        "### 5. Augmentations to be used,\n",
        "        rotation_range=40\n",
        "        width_shift_range=0.2\n",
        "        height_shift_range=0.2\n",
        "        shear_range=0.2\n",
        "        zoom_range=0.2\n",
        "        horizontal_flip=True\n",
        "        fill_mode='nearest'\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvvaSvAGWLga"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"./data/rps/\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "    # FILL: Create the training_datagen ImageDataGenerator, according to the above mentioned requirements.\n",
        "      )\n",
        "\n",
        "VALIDATION_DIR = \"./data/rps-test-set/\"\n",
        "validation_datagen = ImageDataGenerator(\n",
        "      # FILL: Create the validation_datagen ImageDataGenerator, according to the above mentioned requirements.\n",
        "      )\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "    # FILL: Create the train_generator to flow the ImageDataGenerator images from TRAINING_DIR directory, according to the above mentioned requirements.\n",
        "\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    # FILL: Create the train_generator to flow the ImageDataGenerator images from VALIDATION_DIR directory, according to the above mentioned requirements.\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a model according to the below configuration.\n",
        "### Need to have 4 convolutional blocks. Use **ReLU** activation for all convolution layers.\n",
        "  first convolution block:\n",
        "\n",
        "    Kernal Shape= (3,3)\n",
        "    Number of Filters 64\n",
        "  \n",
        "  second convolution block:\n",
        "\n",
        "    Kernal Shape= (3,3)\n",
        "    Number of Filters 64\n",
        "\n",
        "  third convolution block:\n",
        "\n",
        "    Kernal Shape= (3,3)\n",
        "    Number of Filters 128\n",
        "\n",
        "  fourth convolution block:\n",
        "\n",
        "    Kernal Shape= (3,3)\n",
        "    Number of Filters 128\n",
        "\n",
        "### Need to have 2 Dense Layers. Use **ReLU** activation for the first Dense layer. Use a suitable activation function for the Dense final layer.\n",
        "\n",
        "  first dense layer:\n",
        "\n",
        "    Number of Nodes= 512\n",
        "    Activation Function: ReLU\n",
        "    \n",
        "    Note: It is advisable to use dropout with a suitable drop probability for the flattened input; just before feeding into the first dense layer.\n",
        "\n",
        "  second (final) dense layer:\n",
        "\n",
        "    Number of Nodes: Decide based on the Task\n",
        "    Activation Function: Decide based on the Task"
      ],
      "metadata": {
        "id": "-nN4F1GlgQ-c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUdZdTkjphuE"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # FILL: Complete the CNN model based on the above mentioned requirements.\n",
        "    # This is the first convolution block\n",
        "\n",
        "    # The second convolution block\n",
        "\n",
        "    # The third convolution block\n",
        "\n",
        "    # The fourth convolution block\n",
        "\n",
        "    # Flatten the results to feed into a DNN\n",
        "\n",
        "    # Add a Dropout with a suitable probability\n",
        "\n",
        "    # 512 neuron hidden layer\n",
        "\n",
        "    # Output layer with Softmax activation.\n",
        "\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class names order"
      ],
      "metadata": {
        "id": "Eqo-xjMSjGjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU9voNEpFR4D"
      },
      "outputs": [],
      "source": [
        "class_names = sorted(os.listdir('/content/data/rps'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a suitable preprocessing function to,\n",
        "1. resize the given image to the expected input size.\n",
        "2. Normalize images from [0, 255] to [0, 1] range.\n",
        "3. Make sure to expand the first dimension before feeding the image to the NN\n"
      ],
      "metadata": {
        "id": "lHVHvq9qjQvP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hULh8ukD_Y_n"
      },
      "outputs": [],
      "source": [
        "def im_preprocess(img_path, display=False):\n",
        "  # FILL: im_preprocess function.\n",
        "  img = Image.open(img_path).convert('RGB')  # (300, 300, 3)\n",
        "\n",
        "  return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict before training."
      ],
      "metadata": {
        "id": "bjV98ev7j6LA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF_EgZoZ_yeI"
      },
      "outputs": [],
      "source": [
        "im_path = './data/rps/scissors/scissors01-004.png'\n",
        "img = im_preprocess(img_path=im_path, display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op6mhoDJphuF"
      },
      "outputs": [],
      "source": [
        "pred_b4_training = model.predict(img)\n",
        "print(pred_b4_training)\n",
        "print('\\n Prediction before Training:', np.argmax(pred_b4_training))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model."
      ],
      "metadata": {
        "id": "cIO8c9XBkQ04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define tensorboard_callback"
      ],
      "metadata": {
        "id": "JLSKbRqvk_Zg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H87vkvD4-vf6"
      },
      "outputs": [],
      "source": [
        "# Use tensorboard_callback for training.\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OcvKfDrphuG"
      },
      "outputs": [],
      "source": [
        "# FILL: compile model with a suitable Loss Function. Use Adam Optimizer with learning_rate=1e-3\n",
        "model.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt5-O6dlphuG"
      },
      "outputs": [],
      "source": [
        "# FILL: Feed the train_generator to train the model for 25 epochs,\n",
        "# Use validation data to validate the model\n",
        "# Use tensorboard_callback for training.\n",
        "hist = model.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate trained Model"
      ],
      "metadata": {
        "id": "XTt_B0wym5XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILL: Evaluate the model on the test data using `evaluate`. Expected Result: 95+%  Accuracy.\n",
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate()\n",
        "print(\"test loss, test acc:\", results)"
      ],
      "metadata": {
        "id": "KXmySA2mm8Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZhV7D22CEBA"
      },
      "source": [
        "### Save Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvquQhkkdFgw"
      },
      "outputs": [],
      "source": [
        "model.save(\"rps_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIGp59aSG_i3"
      },
      "source": [
        "### Load Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkfyOesgG-HL"
      },
      "outputs": [],
      "source": [
        "trained_model = keras.models.load_model('rps_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Inference after training"
      ],
      "metadata": {
        "id": "HfGv2bhakxGn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aTuTBbxAiTs"
      },
      "outputs": [],
      "source": [
        "im_path = '/content/data/rps-test-set/rock/testrock01-05.png'\n",
        "img = im_preprocess(img_path=im_path, display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T4FbYKEphuG"
      },
      "outputs": [],
      "source": [
        "pred_after_training = trained_model.predict(img)\n",
        "print(pred_after_training)\n",
        "print('\\n Prediction after Training:', class_names[np.argmax(pred_after_training)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk0zMdOKAwQj"
      },
      "outputs": [],
      "source": [
        "im_path = '/content/data/rps-test-set/paper/testpaper01-07.png'\n",
        "img = im_preprocess(img_path=im_path, display=True)\n",
        "\n",
        "pred_after_training = trained_model.predict(img)\n",
        "print(pred_after_training)\n",
        "print('\\n Prediction after Training:', class_names[np.argmax(pred_after_training)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_OX1CLFA61a"
      },
      "outputs": [],
      "source": [
        "im_path = '/content/data/rps-test-set/scissors/testscissors01-10.png'\n",
        "img = im_preprocess(img_path=im_path, display=True)\n",
        "\n",
        "pred_after_training = trained_model.predict(img)\n",
        "print(pred_after_training)\n",
        "print('\\n Prediction after Training:', class_names[np.argmax(pred_after_training)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize training with tensorboard."
      ],
      "metadata": {
        "id": "qboKke_Xk2Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoevdLfN-pbM"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ccFwcF0-raE"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir './logs'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}